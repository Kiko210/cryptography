{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled28.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsawMfdOfaeh"
      },
      "source": [
        "# **Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEt91vHDfmpU"
      },
      "source": [
        "# **Pima Indians Diabetes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQcSA_Bp8PGt"
      },
      "source": [
        "PregnanciesNumber of times pregnant\n",
        "\n",
        "GlucosePlasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "BloodPressureDiastolic blood pressure (mm Hg)\n",
        "\n",
        "SkinThicknessTriceps skin fold thickness (mm)\n",
        "\n",
        "Insulin2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "BMIBody mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "DiabetesPedigreeFunctionDiabetes pedigree function\n",
        "\n",
        "AgeAge (years)\n",
        "\n",
        "OutcomeClass variable (0 or 1) 268 of 768 are 1, the others are 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9thnW8_BfWqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36230317-cba4-4822-93b2-326575ca5824"
      },
      "source": [
        "!git clone https://github.com/deepanrajm/machine_learning.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'machine_learning'...\n",
            "remote: Enumerating objects: 73091, done.\u001b[K\n",
            "remote: Counting objects: 100% (3061/3061), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2863/2863), done.\u001b[K\n",
            "remote: Total 73091 (delta 213), reused 3031 (delta 191), pack-reused 70030 (from 1)\u001b[K\n",
            "Receiving objects: 100% (73091/73091), 127.40 MiB | 15.38 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n",
            "Updating files: 100% (5868/5868), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfWilZ7H8cpE"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ens470-8ge2"
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "# Step 1: Upload and Load Dataset\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Step 2: Separate Features and Labels\n",
        "data = dataset.drop(['Outcome'], axis=1)\n",
        "labels = dataset['Outcome']"
      ],
      "metadata": {
        "id": "tju1yEE-8xvR",
        "outputId": "f1192f55-7f8f-4dbc-e3c7-4d4c4eedb31b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5148e874-14ca-4242-8eec-b92364084de4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5148e874-14ca-4242-8eec-b92364084de4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving diabetes.csv to diabetes (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWrnXLX8mc_"
      },
      "source": [
        "(trainData, testData, trainLabels, testLabels) = train_test_split(data,labels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OE3Aqpw87ts"
      },
      "source": [
        "# **Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZFCXtOXkgqV"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1x5droBZwH8RB4nqE77owjcb3m_aOBgvU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VaRT6hPpPG5"
      },
      "source": [
        "**splitter{“best”, “random”}, default=”best”**\n",
        "\n",
        "The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split.\n",
        "\n",
        "**max_featuresint, float or {“auto”, “sqrt”, “log2”}, default=None**\n",
        "\n",
        "The number of features to consider when looking for the best split:\n",
        "\n",
        "If int, then consider max_features features at each split.\n",
        "\n",
        "If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.\n",
        "\n",
        "If “auto”, then max_features=sqrt(n_features).\n",
        "\n",
        "If “sqrt”, then max_features=sqrt(n_features).\n",
        "\n",
        "If “log2”, then max_features=log2(n_features).\n",
        "\n",
        "If None, then max_features=n_features.\n",
        "\n",
        "*Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9eVrLOt85uD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "face34ec-166c-4fd7-88f2-533ebc4b06e8"
      },
      "source": [
        "#splitter = best, random , max_features = int, auto, log, none\n",
        "model = DecisionTreeClassifier(random_state=84,splitter='best', max_features=8)\n",
        "\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.69      0.74       123\n",
            "           1       0.55      0.68      0.61        69\n",
            "\n",
            "    accuracy                           0.69       192\n",
            "   macro avg       0.67      0.69      0.67       192\n",
            "weighted avg       0.71      0.69      0.69       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMOStwpD9FGs"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9cX7u2p-Is"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1JRk2b-NbpsTbRALKDzIJngfUjOZvj8gk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKdOjYnG9J-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f59ccd-17a8-4113-ebd8-5b85d66f04ae"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=10, random_state=42,max_features=1)\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.83      0.80       123\n",
            "           1       0.66      0.58      0.62        69\n",
            "\n",
            "    accuracy                           0.74       192\n",
            "   macro avg       0.72      0.70      0.71       192\n",
            "weighted avg       0.73      0.74      0.74       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tddo9sY9Nn4"
      },
      "source": [
        "# **KNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhe0Tj4sHYX"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=12O0KRMCL0aO9wIebmPoAmfQdHgLBs4Gt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmi2jHsB9Oo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3117023-e42a-45f7-e5fd-bad5bda31b76"
      },
      "source": [
        "#weights = uniform, weights\n",
        "model = KNeighborsClassifier(n_neighbors=9)\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.76      0.77       123\n",
            "           1       0.60      0.62      0.61        69\n",
            "\n",
            "    accuracy                           0.71       192\n",
            "   macro avg       0.69      0.69      0.69       192\n",
            "weighted avg       0.72      0.71      0.71       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWi5XPe39RIr"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U_5BRZGv_DT"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1I48gEU3IMSFRriv-Uv2qVXy1bJqIrBaz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydWqVAuTwFxt"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1qENQ38k3MwqjAyjc19j-zEvbEIfvYI9Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ll2F_6hwzaz"
      },
      "source": [
        "**The C parameter** trades off correct classification of training examples against maximization of the decision function’s margin. For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words``C`` behaves as a regularization parameter in the SVM\n",
        "\n",
        "\n",
        "**The gamma parameter** defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF3IdqNn9T0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a579a0-f814-48ff-d794-39347e39808a"
      },
      "source": [
        "#kernel='rbf', linear, poly, C=1, gamma='scale'\n",
        "model = SVC(kernel=\"linear\",C=1)\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.78      0.79       123\n",
            "           1       0.62      0.64      0.63        69\n",
            "\n",
            "    accuracy                           0.73       192\n",
            "   macro avg       0.71      0.71      0.71       192\n",
            "weighted avg       0.73      0.73      0.73       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njb9Sy3N9C2G"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HO6v_XqyjSp"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1N2HJHTUlzSj6jqD8b61pYbCYo_rhXaYS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-4fRG-2yS0F"
      },
      "source": [
        "**solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’**\n",
        "Algorithm to use in the optimization problem.\n",
        "\n",
        "For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "\n",
        "For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
        "\n",
        "‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
        "\n",
        "‘liblinear’ and ‘saga’ also handle L1 penalty\n",
        "\n",
        "‘saga’ also supports ‘elasticnet’ penalty\n",
        "\n",
        "‘liblinear’ does not support setting penalty='none'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOsdLirbyM2Y"
      },
      "source": [
        "**penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’**\n",
        "\n",
        "Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JCc9ND1fryj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c07eaa-3518-47ca-a0f6-da8d4372ff4f"
      },
      "source": [
        "#penality = l1,l2, elasticnet\n",
        "#solver = liblinear, sag, saga, lbfgs, newton-cg\n",
        "#max-iter = 100\n",
        "\n",
        "model = LogisticRegression(max_iter=15)#,solver = 'sag')\n",
        "\n",
        "#penalty='l1',solver=\"saga\",max_iter=100\n",
        "\n",
        "print(\"[INFO] training model...\")\n",
        "model.fit(trainData, trainLabels)\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating...\")\n",
        "predictions = model.predict(testData)\n",
        "print(classification_report(testLabels, predictions))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model...\n",
            "[INFO] evaluating...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.86      0.77       123\n",
            "           1       0.56      0.32      0.41        69\n",
            "\n",
            "    accuracy                           0.67       192\n",
            "   macro avg       0.63      0.59      0.59       192\n",
            "weighted avg       0.65      0.67      0.64       192\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}